{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import tensorflow as tf \n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.optimizers import RMSprop\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetSize = 7600\n",
    "testSetSize = 500\n",
    "\n",
    "y2_train = np.empty((dataSetSize,24,144))\n",
    "y2_train_infos = np.empty((dataSetSize,12), dtype=\"O\")\n",
    "y2_train_base = np.empty((dataSetSize,24,144))\n",
    "y2_test = np.empty((testSetSize,24,144))\n",
    "y2_test_infos = np.empty((testSetSize,12), dtype=\"O\")\n",
    "y2_test_base = np.empty((testSetSize,24,144))\n",
    "dataSet = []\n",
    "\n",
    "for i in range(dataSetSize):\n",
    "    dataSet.append(np.load('../TrainingDataset/America/Dataset/y2_{}.npy'.format(i), allow_pickle=True, encoding=\"latin1\"))\n",
    "dataSet = np.asarray(dataSet)\n",
    "\n",
    "\n",
    "for i in range(dataSetSize-testSetSize):\n",
    "    y2_train[i] = dataSet[i][1]\n",
    "    y2_train_base[i] = dataSet[i][0]\n",
    "    y2_train_infos[i] = dataSet[i][2]\n",
    "for i in range(dataSetSize-testSetSize,dataSetSize):\n",
    "    y2_test[i-dataSetSize] = dataSet[i][1]\n",
    "    y2_test_base[i-dataSetSize] = dataSet[i][0]\n",
    "    y2_test_infos[i-dataSetSize] = dataSet[i][2]\n",
    "    \n",
    "nans = np.empty([])\n",
    "for i in range(y2_train.shape[0]):\n",
    "    if math.isnan(np.sum(y2_train[i])):\n",
    "        nans = np.append(nans, i)\n",
    "y2_train = np.delete(y2_train, nans.astype(int), axis=0)    \n",
    "y2_train_base = np.delete(y2_train_base, nans.astype(int), axis=0)\n",
    "y2_train_infos = np.delete(y2_train_infos, nans.astype(int), axis=0)\n",
    "scaler = MinMaxScaler(feature_range=(-1,1), copy=True)\n",
    "for i in range(y2_train.shape[0]):\n",
    "    array = y2_train[i].flatten()\n",
    "    array = scaler.fit_transform(array.reshape(-1, 1))\n",
    "    y2_train[i] = array.reshape(24,144)\n",
    "\n",
    "y2_train = y2_train.reshape(y2_train.shape[0],24,144,1)\n",
    "y2_test = y2_test.reshape(y2_test.shape[0],24,144,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23]\n"
     ]
    }
   ],
   "source": [
    "maskAsia = []\n",
    "datasetAsia = []\n",
    "\n",
    "for a in range(5,11):\n",
    "    datasetAsia.append(np.load('../TrainingDataset/Asia/x_train/y2_{}.npy'.format(a), allow_pickle=True, encoding=\"latin1\"))\n",
    "    datasetAsia[a-5] = np.asarray(datasetAsia[a-5][0]).reshape(24,144,1)\n",
    "datasetAsia = np.asarray(datasetAsia)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(datasetAsia[5].shape[0]):\n",
    "    if math.isnan(np.sum(datasetAsia[1][i])):\n",
    "        maskAsia.append(i)\n",
    "        \n",
    "print(maskAsia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Encoder\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Decoder\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(16, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "    masked_img = Input(shape=img_shape)\n",
    "    gen_missing = model(masked_img)\n",
    "#     plot_model(model, to_file='model_plot.png', show_shapes=True)\n",
    "    return Model(masked_img, gen_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=missing_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.summary()\n",
    "\n",
    "    img = Input(shape=missing_shape)\n",
    "    validity = model(img)\n",
    "#     plot_model(model, to_file='model_plot.png', show_shapes=True)\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy_label_smoothing(y_true, y_pred):\n",
    "    return tf.losses.binary_crossentropy(y_true, y_pred, label_smoothing=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 24\n",
    "img_cols = 144\n",
    "mask_height = 24\n",
    "mask_width = 144\n",
    "channels = 1\n",
    "num_classes = 2\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "missing_shape = (mask_height, mask_width, channels)\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# # For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "# 'binary_crossentropy'\n",
    "discriminator.compile(loss=binary_crossentropy_label_smoothing,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# The generator takes noise as input and generates the missing\n",
    "# part of the image\n",
    "masked_img = Input(shape=img_shape)\n",
    "gen_missing = generator(masked_img)\n",
    "\n",
    "# # The discriminator takes generated images as input and determines\n",
    "# # if it is generated or if it is a real image\n",
    "valid = discriminator(gen_missing)\n",
    "\n",
    "# # # The combined model  (stacked generator and discriminator)\n",
    "# # # Trains generator to fool discriminator\n",
    "combined = Model(masked_img , [gen_missing, valid])\n",
    "combined.compile(loss=['mse', binary_crossentropy_label_smoothing],\n",
    "    loss_weights=[0.999, 0.001],\n",
    "    optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_asia(imgs, mask):\n",
    "    masked_imgs = np.empty_like(imgs)\n",
    "    missing_parts = np.full_like(imgs, 0)\n",
    "    for i, img in enumerate(imgs):\n",
    "        masked_img = img.copy().reshape(24,144)\n",
    "        for line in mask:\n",
    "            missing_parts[i][line] = img[line].copy()\n",
    "            masked_img[line] = np.full(img.shape[1], 0)\n",
    "        masked_imgs[i] = masked_img.reshape(24,144,1)\n",
    "    return masked_imgs, missing_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_randomly(imgs):\n",
    "    y1 = np.random.randint(0, img_rows - mask_height, imgs.shape[0])\n",
    "    y2 = y1 + mask_height\n",
    "    x1 = np.full([imgs.shape[0]],0)\n",
    "    x2 = x1 + mask_width\n",
    "\n",
    "    masked_imgs = np.empty_like(imgs)\n",
    "    missing_parts = np.empty((imgs.shape[0], mask_height, mask_width, channels))\n",
    "    for i, img in enumerate(imgs):\n",
    "        masked_img = img.copy()\n",
    "        _y1, _y2, _x1, _x2 = y1[i], y2[i], x1[i], x2[i]\n",
    "        missing_parts[i] = masked_img[_y1:_y2, _x1:_x2, :].copy()\n",
    "        masked_img[_y1:_y2, _x1:_x2, :] = 0\n",
    "        masked_imgs[i] = masked_img\n",
    "\n",
    "    return masked_imgs, missing_parts, (y1, y2, x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = y2_train.copy()\n",
    "def train(epochs, batch_size=128, sample_interval=50, label_switching=False):\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs+1):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        \n",
    "        masked_imgs, missing_parts = mask_asia(imgs, maskAsia)\n",
    "        if not math.isnan(np.sum(imgs)) and not math.isnan(np.sum(masked_imgs)):\n",
    "            # Generate a batch of new images\n",
    "            gen_missing = generator.predict(masked_imgs)\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch(missing_parts, valid)\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_missing, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = combined.train_on_batch(masked_imgs, [missing_parts, valid])\n",
    "\n",
    "            # Plot the progress\n",
    "            clear_output(wait=True)\n",
    "            print (\"%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0], g_loss[1]))\n",
    "            if epoch % sample_interval == 0:\n",
    "                imgs = datasetAsia\n",
    "                sample_images(epoch, imgs)\n",
    "        else:\n",
    "            print(\"nan value in training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(epoch, imgs):\n",
    "    r, c = 3, 6\n",
    "\n",
    "    masked_imgs, missing_parts = mask_asia(imgs, maskAsia)\n",
    "    gen_missing = generator.predict(masked_imgs)\n",
    "\n",
    "    imgs = 0.5 * imgs + 0.5\n",
    "    masked_imgs = 0.5 * masked_imgs + 0.5\n",
    "    gen_missing = 0.5 * gen_missing + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.1)\n",
    "    fig.set_size_inches(20,3)\n",
    "    for i in range(c):\n",
    "        axs[0,i].imshow(imgs[i, :,:].reshape(24,144),cmap=plt.get_cmap('jet', 20))\n",
    "        axs[1,i].imshow(masked_imgs[i, :,:].reshape(24, 144),cmap=plt.get_cmap('jet', 20))\n",
    "        filled_in = imgs[i].copy()\n",
    "        for line in maskAsia:\n",
    "            filled_in[line] = gen_missing[i][line].copy()\n",
    "        axs[2,i].imshow(filled_in.reshape(24, 144),cmap=plt.get_cmap('jet', 20))\n",
    "    fig.savefig(\"../NN_training/CEGAN_lines/%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    def save(model, model_name):\n",
    "        model_path = \"saved_model_CEGAN/%s.json\" % model_name\n",
    "        weights_path = \"saved_model_CEGAN/%s_weights.hdf5\" % model_name\n",
    "        options = {\"file_arch\": model_path,\n",
    "                    \"file_weight\": weights_path}\n",
    "        json_string = model.to_json()\n",
    "        open(options['file_arch'], 'w').write(json_string)\n",
    "        model.save_weights(options['file_weight'])\n",
    "\n",
    "    save(generator, \"generator\")\n",
    "    save(discriminator, \"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 [D loss: 1.060692, acc: 50.78%] [G loss: 0.027957, mse: 0.027495]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6dbcc0f2cced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_switching\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b1c25d523f46>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, sample_interval, label_switching)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmissing_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Plot the progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow_core/python/keras/backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow_core/python/eager/function.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow_core/python/eager/function.pyc\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow_core/python/eager/function.pyc\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow_core/python/eager/function.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/home/cristille/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow_core/python/eager/execute.pyc\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs=1000, batch_size=64, sample_interval=10, label_switching=False)\n",
    "save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7 matlab",
   "language": "python",
   "name": "dlwp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
